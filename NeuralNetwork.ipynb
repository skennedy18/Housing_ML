{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e47a6c0e8bd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Tensorflow for modelling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tensorflow version : {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = df_train.drop(['SalePrice'], axis=1)\n",
    "y = df_train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=pd.concat([train, df_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print each shape of data\n",
    "print(\"The shape of data train : {} \".format(df_train.shape))\n",
    "print(\"The shape of data test : {} \".format(df_test.shape))\n",
    "print(\"The shape of all data (label excluded) : {} \".format(data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train.describe(include=['object', 'bool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.sort_values(by='SalePrice', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_analysis = {'Year Sold':['2006', '2007', '2008', '2009', '2010'],\n",
    "               'Mean Sale Price': [round(df_train.query('YrSold == 2006').SalePrice.mean()),\n",
    "                            round(df_train.query('YrSold == 2007').SalePrice.mean()),\n",
    "                            round(df_train.query('YrSold == 2008').SalePrice.mean()),\n",
    "                            round(df_train.query('YrSold == 2009').SalePrice.mean()),\n",
    "                            round(df_train.query('YrSold == 2010').SalePrice.mean())],\n",
    "               'Min Sale Price': [df_train.query('YrSold == 2006').SalePrice.min(),\n",
    "                                  df_train.query('YrSold == 2007').SalePrice.min(),\n",
    "                                  df_train.query('YrSold == 2008').SalePrice.min(),\n",
    "                                  df_train.query('YrSold == 2009').SalePrice.min(),\n",
    "                                  df_train.query('YrSold == 2010').SalePrice.min()],\n",
    "               'Max Sale Price': [df_train.query('YrSold == 2006').SalePrice.max(),\n",
    "                                  df_train.query('YrSold == 2007').SalePrice.max(),\n",
    "                                  df_train.query('YrSold == 2008').SalePrice.max(),\n",
    "                                  df_train.query('YrSold == 2009').SalePrice.max(),\n",
    "                                  df_train.query('YrSold == 2010').SalePrice.max()]}\n",
    "df_temp = pd.DataFrame(df_analysis, index=['1', '2', '3', '4', '5'])\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set(style='whitegrid')\n",
    "sns.lineplot(x=\"Year Sold\", y=\"Mean Sale Price\", \n",
    "                  data=df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(df_train.columns), 4):\n",
    "    sns.pairplot(data=df_train,\n",
    "                x_vars=df_train.columns[i:i+4],\n",
    "                y_vars=['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d120364a0412>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Find the percentage of NaN value in data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# check target nan value in the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m nan_percentage = combined.isnull().sum().sort_values(\n\u001b[1;32m      5\u001b[0m     ascending=False) / combined.shape[0]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "combined = data.copy()\n",
    "nan_percentage = combined.isnull().sum().sort_values(\n",
    "    ascending=False) / combined.shape[0]\n",
    "missing_val = nan_percentage[nan_percentage > 0]\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "sns.barplot(x=missing_val.index.values, \n",
    "            y=missing_val.values * 100, \n",
    "            palette=\"Reds_r\");\n",
    "plt.title(\"Percentage of missing values in data\");\n",
    "plt.ylabel(\"%\");\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['PoolQC','MiscFeature','Alley','Fence','FireplaceQu'],\n",
    "          axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Id'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_col = data.columns[data.isnull().any()].tolist()\n",
    "data[nan_col].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking care NaN value with type is float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The strategy : replace with the average of that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.fillna(data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = df.copy()\n",
    "nan_percentage = combined.isnull().sum().sort_values(\n",
    "    ascending=False) / combined.shape[0]\n",
    "missing_val = nan_percentage[nan_percentage > 0]\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "sns.barplot(x=missing_val.index.values, \n",
    "            y=missing_val.values * 100, \n",
    "            palette=\"Reds_r\");\n",
    "plt.title(\"Percentage of missing values in data\");\n",
    "plt.ylabel(\"%\");\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking care NaN value with type is Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The strategy : replace with mode of that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_col = df.columns[df.isnull().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in nan_col:\n",
    "    df[column].fillna(df[column].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns=df.select_dtypes(exclude=['O']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numerical_columns].sample(5, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df):\n",
    "  numerical_columns=df.select_dtypes(exclude=['O']).columns\n",
    "\n",
    "  scaling=MinMaxScaler()\n",
    "  df[numerical_columns]=scaling.fit_transform(df[numerical_columns])\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_norm = normalize_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_norm[numerical_columns].sample(5, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm.sample(5, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns=df_norm.select_dtypes(include=['O']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sklearn as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(s.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_transformer = make_column_transformer(\n",
    "    (OneHotEncoder(), categorical_columns),\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_encoded = column_transformer.fit_transform(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data type from sparse into DataFrame\n",
    "import scipy.sparse\n",
    "df_encode = pd.DataFrame.sparse.from_spmatrix(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encode.sample(5, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_encode.iloc[:-len(df_test), :]\n",
    "X_test = df_encode.iloc[len(df_train):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nOld data\")\n",
    "print(\"The shape of data train : {} \".format(df_train.shape))\n",
    "print(\"The shape of data test : {} \".format(df_test.shape))\n",
    "\n",
    "print(\"\\nNew data\")\n",
    "print(\"The shape of data train : {} \".format(X_train.shape))\n",
    "print(\"The shape of data test : {} \".format(X_test.shape))\n",
    "\n",
    "print(\"The shape of class : {} \".format(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(512, kernel_initializer='normal',\n",
    "                   input_dim = X_train.shape[1], \n",
    "                   activation='relu'))\n",
    "\n",
    " \n",
    "model.add(Dense(216, kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(216, kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(128, kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(64, kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    " \n",
    "model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_absolute_error', \n",
    "                 optimizer='adam', \n",
    "                 metrics=['mean_absolute_error'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filepath = 'model.{epoch:02d}-{val_loss:.2f}.h5'\n",
    "callback = ModelCheckpoint(filepath, \n",
    "                             monitor='val_loss', \n",
    "                             verbose = 1, \n",
    "                             save_best_only = True, \n",
    "                             mode ='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model.fit(X_train, y, \n",
    "             epochs=1000, \n",
    "             batch_size=32, \n",
    "             validation_split = 0.25, \n",
    "             callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['SalePrice'] = predictions\n",
    "submission.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the prediction\n",
    "submission.to_csv('Submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
